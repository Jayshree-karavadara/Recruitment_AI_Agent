# Recruitment AI Agent

# Recruitment AI Agent

## 1. Project Vision and Core Philosophy

**Objective:** To construct a fully functional Recruitment AI Agent as a web application. The application will allow a user to provide a job description (JD) and multiple resumes, and in return, receive a ranked list of candidates with an AI-powered analysis for each.

**Guiding Principles:** This project is built adhering to principles of modern software engineering, inspired by the "Clean Code" philosophy and production-ready architectures.

-   **Modularity & Single Responsibility:** Each component (file/class) has one, and only one, reason to change. The code that handles LLM calls is separate from the code that processes files, which is separate from the web-handling code.
-   **Configuration-Driven:** No hardcoded values. All settings—such as model names, provider choices, and especially LLM prompts—are externalized into configuration files. This allows for easy modification without changing the application's source code.
-   **Abstraction & Decoupling:** The application is not tied to a single AI provider (like OpenAI or Groq). An abstraction layer allows us to switch between providers effortlessly.
-   **Clarity and Maintainability:** The project structure and naming conventions are intuitive, making the codebase easy to understand, test, and extend.

## 2. Core Technology Stack

-   **Backend Framework:** FastAPI (for its speed, async capabilities, and automatic documentation).
-   **Frontend Rendering:** Jinja2 (for simple, server-side HTML rendering).
-   **Package Management:** uv (for its high-speed dependency management and environment creation).
-   **Document Conversion:** The markitdown library (to convert various file formats like PDF and DOCX into clean Markdown).
-   **Configuration:** YAML files (PyYAML library) for settings and prompts.
-   **AI Providers:** OpenAI (using the `openai` Python SDK) and Groq (using the `groq` Python SDK).
-   **Secrets Management:** A `.env` file using the `python-dotenv` library.

## 3. Architectural Blueprint (File Structure)

```
recruitment_ai_agent/
├── config/
│   ├── settings.yaml            # Defines the AI provider, model names, and other non-secret settings.
│   └── prompts.yaml             # The single source of truth for all LLM prompts.
│
├── src/
│   ├── api/
│   │   ├── __init__.py
│   │   ├── routes.py            # The web layer. Handles HTTP requests and responses. No business logic.
│   │   └── schemas.py           # Pydantic models for data validation and structured API responses.
│   │
│   ├── core/
│   │   ├── __init__.py
│   │   ├── document_processor.py # Solely responsible for converting files to Markdown text.
│   │   └── evaluation_engine.py  # The central orchestrator of the application's business logic.
│   │
│   ├── llm/
│   │   ├── __init__.py            # A factory to create and return the configured LLM client.
│   │   ├── base.py                # Defines the abstract "contract" (interface) for any LLM client.
│   │   ├── openai_client.py       # The concrete implementation for the OpenAI API.
│   │   └── groq_client.py         # The concrete implementation for the Groq API.
│   │
│   ├── prompts/
│   │   ├── __init__.py
│   │   └── manager.py             # Responsible for loading, parsing, and formatting prompts from prompts.yaml.
│   │
│   └── utils/
│       └── logger.py              # Configures a centralized, application-wide logger.
│
├── data/
│   └── uploads/                 # A temporary directory for storing uploaded files during processing.
│
├── templates/
│   └── index.html               # The Jinja2 HTML template for the user interface.
│
├── static/
│   └── styles.css               # Basic CSS for the frontend.
│
├── main.py                      # The main entry point that initializes and runs the FastAPI app.
├── .env                         # Stores secrets: OPENAI_API_KEY and GROQ_API_KEY.
├── pyproject.toml               # Project metadata and dependencies for uv.
├── requirements.txt             # Project dependencies generated by pipreqs.
└── README.md                    # Project documentation.
```

## 4. Component Deep Dive: Logic and Responsibilities

### A. The Configuration Layer (`/config`)

-   **`settings.yaml`**: This file controls the application's behavior. It contains keys for the default AI provider and the specific model names for each provider.
    ```yaml
    ai:
      default_provider: "groq" # or "openai"
      models:
        openai: "gpt-5-mini"
        groq: "openai/gpt-oss-120b"
    ```

-   **`prompts.yaml`**: This file externalizes all prompt engineering. It contains structured entries for each task and uses placeholders (e.g., `{jd_text}`) that the application fills in.
    ```yaml
    resume_evaluation:
      system_prompt: "You are an expert AI Recruitment Assistant. Your task is to analyze a candidate's resume against a job description and provide a structured JSON response. Do not include any explanatory text outside of the JSON object."
      user_prompt: |
        Job Description:
        ---
        {jd_text}
        ---
        Candidate Resume:
        ---
        {resume_text}
        ---
        Analyze the resume and return ONLY a JSON object with the following keys: "score" (integer 0-100), "missing_skills" (an array of strings), and "remarks" (a brief 30-word summary).

    jd_generation:
      # ... prompt for generating a JD
    interview_email:
      # ... prompt for generating an interview email
    rejection_email:
      # ... prompt for generating a rejection email
    ```

### B. The LLM Abstraction Layer (`/src/llm`)

-   **`base.py`**:
    -   **Purpose:** Defines a mandatory "contract" or interface that all LLM clients MUST follow.
    -   **Logic:** Contains an Abstract Base Class (ABC) named `LLMClient` with abstract methods like `evaluate_resume(self, jd_text: str, resume_text: str) -> dict`.

-   **`openai_client.py` & `groq_client.py`**:
    -   **Purpose:** Implement the `LLMClient` contract for their specific APIs.
    -   **Logic:** Each has a class (e.g., `OpenAIClient`) that inherits from `LLMClient`. The `__init__` method initializes the official SDK client, and the `evaluate_resume` method constructs the API request, makes the call, parses the JSON response, and handles errors.

-   **`__init__.py` (The Factory)**:
    -   **Purpose:** The single point of entry for the rest of the app to get an LLM client.
    -   **Logic:** Contains a `get_llm_client()` function that reads `default_provider` from `settings.yaml`, loads the appropriate API key from `.env`, and returns an initialized instance of either `OpenAIClient` or `GroqClient`.

### C. The Core Business Logic Layer (`/src/core`)

-   **`document_processor.py`**:
    -   **Purpose:** Its only job is to convert files into text.
    -   **Logic:** Contains a `DocumentProcessor` class with a `process(file_stream: BytesIO) -> str` method that uses the `markitdown` library for conversion.

-   **`evaluation_engine.py`**:
    -   **Purpose:** The central nervous system of the application, orchestrating the entire evaluation process.
    -   **Logic:** Contains an `EvaluationEngine` class. Its `__init__` method uses Dependency Injection, being initialized with `LLMClient`, `DocumentProcessor`, and `PromptManager` instances. The primary method, `evaluate_candidates(jd_file: UploadFile, resume_files: list[UploadFile]) -> list[dict]`, extracts text from files, calls the LLM client for evaluation, adds filenames to results, sorts them by score, and returns the sorted list.

### D. The API and Presentation Layer (`/src/api`, `/templates`)

-   **`api/schemas.py`**: Defines Pydantic models (e.g., `CandidateResult`, `EvaluationResult`) for data validation and structured API responses.

-   **`api/routes.py`**:
    -   **Purpose:** Handles web traffic and connects the HTTP world to the application's core logic.
    -   **Logic:** Defines FastAPI endpoints:
        -   `GET /`: Renders the `index.html` template.
        -   `POST /evaluate`: Accepts JD and resume files, instantiates `EvaluationEngine`, calls `evaluate_candidates()`, and renders `index.html` with the results.

-   **`templates/index.html`**:
    -   **Purpose:** The user interface.
    -   **Logic:** Uses Jinja2 templating for an HTML form with file uploads. Displays evaluation results in a loop, highlighting the top-scoring candidate.

## Setup

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/Jayshree-karavadara/Recruitment_AI_Agent.git
    cd Recruitment_AI_Agent
    ```

2.  **Set up and activate the virtual environment:**  # any environment conda or venv

# create conda env
conda create -n recruitment_env python=3.11 -y

# activate conda activate 
conda activate recruitment_env


4.  **Install dependencies:**
    ```bash
    # Using pip (if you used python -m venv)
    pip install -r requirements.txt

5.  **Configure the application:**

    a. Create a `.env` file in the root directory:
    ```
    OPENAI_API_KEY="your_openai_api_key"
    GROQ_API_KEY="your_groq_api_key"
    ```

    b. Configure settings (optional):
    - Edit `config/settings.yaml` to set the default AI provider and model names
    - Edit `config/prompts.yaml` to customize the AI prompts

6.  **Run the application:**
    ```bash
    python main.py
    ```
    The application will be available at `http://127.0.0.1:8000`
